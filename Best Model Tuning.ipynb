{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad71475a",
   "metadata": {},
   "source": [
    "import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6609c8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import joblib\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f555dad2",
   "metadata": {},
   "source": [
    "import,check, split, and scale the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "19aaedac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (8000, 6)\n",
      "X_test shape: (2000, 6)\n",
      "y_train shape: (8000,)\n",
      "y_test shape: (2000,)\n"
     ]
    }
   ],
   "source": [
    "#Load the data\n",
    "df = pd.read_csv(r'C:\\Users\\james\\Documents\\Capstone\\Final\\synthetic_email_data.csv')\n",
    "\n",
    "folder_path =r'C:\\Users\\james\\Documents\\Capstone\\Final'\n",
    "\n",
    "# Prepare for Scaling and Splitting\n",
    "\n",
    "# Ensure correct data types\n",
    "df['subscriber_id'] = df['subscriber_id'].astype(int)\n",
    "df['email_frequency_per_week'] = df['email_frequency_per_week'].astype(int)\n",
    "df['email_send_hour'] = df['email_send_hour'].astype(int)\n",
    "df['personalized'] = df['personalized'].astype(int)\n",
    "#df['spam_complaints'] = df['spam_complaints'].astype(int)\n",
    "df['time_in_business'] = df['time_in_business'].astype(int)\n",
    "df['unsubscribe'] = df['unsubscribe'].astype(int)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(['subscriber_id', 'unsubscribe'], axis=1)\n",
    "y = df['unsubscribe']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Display the shapes of the resulting datasets\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad1df8e",
   "metadata": {},
   "source": [
    "initialize and train the best model from scratch work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a2b46017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting\n",
      "Accuracy: 0.8215\n",
      "Precision: 0.9776\n",
      "Recall: 0.4665\n",
      "F1 Score: 0.6316\n",
      "\n",
      "Random Forest\n",
      "Accuracy: 0.8000\n",
      "Precision: 0.8000\n",
      "Recall: 0.4590\n",
      "F1 Score: 0.5833\n"
     ]
    }
   ],
   "source": [
    "#initialize model\n",
    "GB_Classifier = GradientBoostingClassifier(random_state=42)\n",
    "RF_Classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "#Fit the model\n",
    "GB_Classifier.fit(X_train_scaled, y_train)\n",
    "RF_Classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "gb_y_pred = GB_Classifier.predict(X_test_scaled)\n",
    "rf_y_pred = RF_Classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "gb_accuracy = accuracy_score(y_test, gb_y_pred)\n",
    "gb_precision = precision_score(y_test, gb_y_pred)\n",
    "gb_recall = recall_score(y_test, gb_y_pred)\n",
    "gb_f1 = f1_score(y_test, gb_y_pred)\n",
    "\n",
    "# Evaluate the model\n",
    "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "rf_precision = precision_score(y_test, rf_y_pred)\n",
    "rf_recall = recall_score(y_test, rf_y_pred)\n",
    "rf_f1 = f1_score(y_test, rf_y_pred)\n",
    "\n",
    "print(\"\\nGradient Boosting\")\n",
    "print(f\"Accuracy: {gb_accuracy:.4f}\")\n",
    "print(f\"Precision: {gb_precision:.4f}\")\n",
    "print(f\"Recall: {gb_recall:.4f}\")\n",
    "print(f\"F1 Score: {gb_f1:.4f}\")\n",
    "\n",
    "print(\"\\nRandom Forest\")\n",
    "print(f\"Accuracy: {rf_accuracy_gb:.4f}\")\n",
    "print(f\"Precision: {rf_precision_gb:.4f}\")\n",
    "print(f\"Recall: {rf_recall_gb:.4f}\")\n",
    "print(f\"F1 Score: {rf_f1_gb:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd54e96",
   "metadata": {},
   "source": [
    "Test different parameters for the gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6adfab81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Gradient Boosting: {'learning_rate': 0.14, 'max_depth': 1, 'min_samples_leaf': 2, 'min_samples_split': 9, 'n_estimators': 175}\n",
      "Best score for Gradient Boosting: 0.6596143675784937\n",
      "Best parameters for Random Forest: {'max_depth': 15, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 54}\n",
      "Best score for Random Forest: 0.6603297152637864\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid for Gradient Boosting\n",
    "param_grid_gb = {\n",
    "    'n_estimators': randint(50, 500),\n",
    "    'learning_rate': [round(random.uniform(0.1, 0.3), 2) for _ in range(10)],\n",
    "    'max_depth': randint(1, 20),\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 10)\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': randint(50, 500),\n",
    "    'max_depth': randint(1, 20),\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 10)\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV for Random Forest\n",
    "random_search_rf = RandomizedSearchCV(RandomForestClassifier(random_state=42), \n",
    "                                      param_distributions=param_grid_rf, \n",
    "                                      scoring='f1', \n",
    "                                      n_jobs=4,\n",
    "                                      n_iter=100,  \n",
    "                                      random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV for Gradient Boosting\n",
    "random_search_gb = RandomizedSearchCV(GradientBoostingClassifier(random_state=42), \n",
    "                                      param_distributions=param_grid_gb, \n",
    "                                      scoring='f1', \n",
    "                                      n_jobs=4,\n",
    "                                      n_iter=100, \n",
    "                                      random_state=42)\n",
    "\n",
    "# Fit RandomizedSearchCV for Gradient Boosting\n",
    "random_search_gb.fit(X_train_scaled, y_train)\n",
    "print(\"Best parameters for Gradient Boosting:\", random_search_gb.best_params_)\n",
    "print(\"Best score for Gradient Boosting:\", random_search_gb.best_score_)\n",
    "\n",
    "# Fit RandomizedSearchCV for Random Forest\n",
    "random_search_rf.fit(X_train_scaled, y_train)\n",
    "print(\"Best parameters for Random Forest:\", random_search_rf.best_params_)\n",
    "print(\"Best score for Random Forest:\", random_search_rf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5803bb64",
   "metadata": {},
   "source": [
    "Apply best parameters to Gradient boosting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3c07a957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting\n",
      "Accuracy: 0.8250\n",
      "Precision: 0.9968\n",
      "Recall: 0.4680\n",
      "F1 Score: 0.6369\n",
      "\n",
      "Radom Forest\n",
      "Accuracy: 0.8240\n",
      "Precision: 0.9935\n",
      "Recall: 0.4665\n",
      "F1 Score: 0.6349\n",
      "\n",
      "Gradient Boosting model saved to: C:\\Users\\james\\Documents\\Capstone\\Final\\gradient_boosting_model.pkl\n",
      "Scaler saved to: C:\\Users\\james\\Documents\\Capstone\\Final\\scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "#initialize model\n",
    "GB_Classifier2 = GradientBoostingClassifier(\n",
    "    learning_rate=0.14, \n",
    "    max_depth=1, \n",
    "    min_samples_leaf=2, \n",
    "    min_samples_split=9, \n",
    "    n_estimators=175, \n",
    "    random_state=42\n",
    ")\n",
    "RF_Classifier2 = RandomForestClassifier(\n",
    "    max_depth=15, \n",
    "    min_samples_leaf=3, \n",
    "    min_samples_split=2, \n",
    "    n_estimators=54, \n",
    "    random_state=42)\n",
    "\n",
    "\n",
    "#Fit the model\n",
    "GB_Classifier2.fit(X_train_scaled, y_train)\n",
    "RF_Classifier2.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "gb_y_pred2 = GB_Classifier2.predict(X_test_scaled)\n",
    "rf_y_pred2 = RF_Classifier2.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "gb_accuracy2 = accuracy_score(y_test, gb_y_pred2)\n",
    "gb_precision2 = precision_score(y_test, gb_y_pred2)\n",
    "gb_recall2 = recall_score(y_test, gb_y_pred2)\n",
    "gb_f12 = f1_score(y_test, gb_y_pred2)\n",
    "\n",
    "# Evaluate the model\n",
    "rf_accuracy2 = accuracy_score(y_test, rf_y_pred2)\n",
    "rf_precision2 = precision_score(y_test, rf_y_pred2)\n",
    "rf_recall2 = recall_score(y_test, rf_y_pred2)\n",
    "rf_f12 = f1_score(y_test, rf_y_pred2)\n",
    "\n",
    "print(\"\\nGradient Boosting\")\n",
    "print(f\"Accuracy: {gb_accuracy2:.4f}\")\n",
    "print(f\"Precision: {gb_precision2:.4f}\")\n",
    "print(f\"Recall: {gb_recall2:.4f}\")\n",
    "print(f\"F1 Score: {gb_f12:.4f}\")\n",
    "\n",
    "print(\"\\nRadom Forest\")\n",
    "print(f\"Accuracy: {rf_accuracy2:.4f}\")\n",
    "print(f\"Precision: {rf_precision2:.4f}\")\n",
    "print(f\"Recall: {rf_recall2:.4f}\")\n",
    "print(f\"F1 Score: {rf_f12:.4f}\")\n",
    "\n",
    "# Save the models\n",
    "model_path = os.path.join(folder_path, 'gradient_boosting_model.pkl')\n",
    "model_path2 = os.path.join(folder_path, 'Random_Forest.pkl')\n",
    "joblib.dump(GB_Classifier2, model_path)\n",
    "joblib.dump(RF_Classifier2, model_path2)                           \n",
    "print(\"\\nGradient Boosting model saved to:\", model_path)\n",
    "\n",
    "# Save the scaler\n",
    "scaler_path = os.path.join(folder_path, 'scaler.pkl')\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(\"Scaler saved to:\", scaler_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
